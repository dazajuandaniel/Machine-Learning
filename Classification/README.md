# Classification
This subfolder contains some of the code that I have done using Naive Bayes, Decision Trees, Random Forest and others. As of now, I have only added the code done for my course in the master degree.

# Files Included
[Naive Bayes](https://github.com/dazajuandaniel/Machine-Learning/blob/master/Classification/Naive%20Bayes%20Twitter%20Sentiment.ipynb) Using Naive Bayes to classify the sentiment of a tweet. The main goal ***was not*** to build the perfect classifier, rather it was to understand the behavior of the current classifier based on the underlying assumptions of the model. The dataset consisted of a set of tweets which had already been processed, meaning the feature engineering aspect of this was out of scope. Data was treated as is.

[Decision Trees](https://github.com/dazajuandaniel/Machine-Learning/blob/master/Classification/Decision%20Tree%20Twitter%20Sentiment.ipynb) Similar to Naive Bayes, the purpose was to understand the behavior.

[Predictive Maintenance](https://github.com/dazajuandaniel/Machine-Learning/blob/master/Classification/Predictive%20Maintenance.ipynb) This is still a Work In Progress. Eventually, it will contain a PM model using the NASA dataset.

# Report
The nature of this task is not to build the perfect algorithm, but to be able to analyze effectively the outcomes of the different models. The report showcases, in less than 1700 words, the analysis performed to the different algorithms. Critical thinking and analysis is at times more important than being able to use the libraries. ***Understanding*** the assumptions and pitfalls of the various algorithms is crucial to production-grade developments.

# Notice
Please make sure that if you use any part of the report that you abide by the University of Melbourne rules.
You can find more [here](http://academicintegrity.unimelb.edu.au/)

## Programming Language
All of this code is developed in Python.